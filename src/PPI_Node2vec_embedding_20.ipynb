{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef28a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,Linear,RGCNConv\n",
    "from torch_geometric.nn import GAE, Node2Vec,VGAE\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn.models.autoencoder import ARGVA\n",
    "\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167995cc-eaf5-4878-80de-fc4caf59bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x293f1e6e5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9289db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df=pd.read_csv('PPI.csv')\n",
    "G=nx.from_pandas_edgelist(df,'Official Symbol Interactor A','Official Symbol Interactor B' )\n",
    "#Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "#G0 = G.subgraph(Gcc[0])\n",
    "G=nx.convert_node_labels_to_integers(G)\n",
    "pyg_graph = from_networkx(G)\n",
    "\n",
    "node_embedding=Node2Vec(pyg_graph.edge_index,20,16,10)\n",
    "\n",
    "#embedding del nodo 0\n",
    "#node_embedding.forward().data[0]# cambia ogni volta anche con il seed \n",
    "\n",
    "#aggiungiamo gli embedding come features dei nodi\n",
    "for n in G.nodes():\n",
    "    G.nodes[n]['x']=np.array(node_embedding.forward().data[n])\n",
    "    \n",
    "pyg_graph = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566b7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(is_undirected=False,split_labels=True,\n",
    "                      neg_sampling_ratio=1.0,\n",
    "                      key = \"edge_label\",\n",
    "                      disjoint_train_ratio=0,\n",
    "                      num_val =0)\n",
    "train_data, val_data, test_data = transform(pyg_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98d77963-15ef-4ec4-a386-00dc804efa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[19776, 20], edge_index=[2, 1118815], pos_edge_label=[1118815], pos_edge_label_index=[2, 1118815], neg_edge_label=[1118815], neg_edge_label_index=[2, 1118815])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd36dd2-a0de-4d53-b09c-f6a2cc8e4d16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE handmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40f5b37d-2dd3-4786-98ad-80f389a764ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e429918-f058-4e86-83fb-403fffcc6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def encode(self,data):\n",
    "        x = self.conv1(data.x, data.edge_index) # convolution 1\n",
    "        x = x.relu()\n",
    "        return self.conv2(x, data.edge_index) # convolution 2\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z): \n",
    "        prob_adj = z @ z.t() # get adj NxN\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7aeae920-3b55-4566-b750-8932c8178616",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model= Net(num_features, out_channels).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9cb1411-e695-4f98-b8c2-70e3684d74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    # returns a tensor:\n",
    "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
    "    # and the number of zeros is equal to the length of neg_edge_index\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "\n",
    "    #neg_edge_index = negative_sampling(\n",
    "    #    edge_index=train_data.train_pos_edge_index, #positive edges\n",
    "    #    num_nodes=train_data.num_nodes, # number of nodes\n",
    "    #    num_neg_samples=train_data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode(data) #encode\n",
    "    link_logits = model.decode(z, data.pos_edge_label_index, data.neg_edge_label_index) # decode\n",
    "    \n",
    "    link_labels = get_link_labels(data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index    \n",
    "    link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
    "    link_probs = link_logits.sigmoid() # apply sigmoid\n",
    "    link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
    "\n",
    "    return roc_auc_score(link_labels.cpu(), link_probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f262967d-392b-41ab-8375-5d1553497b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6897,auc: 0.7607\n",
      "Epoch: 002, Loss: 0.6809,auc: 0.7657\n",
      "Epoch: 003, Loss: 0.6732,auc: 0.7766\n",
      "Epoch: 004, Loss: 0.6713,auc: 0.7912\n",
      "Epoch: 005, Loss: 0.6657,auc: 0.8063\n",
      "Epoch: 006, Loss: 0.6572,auc: 0.8212\n",
      "Epoch: 007, Loss: 0.6489,auc: 0.8346\n",
      "Epoch: 008, Loss: 0.6418,auc: 0.8456\n",
      "Epoch: 009, Loss: 0.6346,auc: 0.8540\n",
      "Epoch: 010, Loss: 0.6267,auc: 0.8608\n",
      "Epoch: 011, Loss: 0.6194,auc: 0.8668\n",
      "Epoch: 012, Loss: 0.6131,auc: 0.8721\n",
      "Epoch: 013, Loss: 0.6062,auc: 0.8766\n",
      "Epoch: 014, Loss: 0.5986,auc: 0.8800\n",
      "Epoch: 015, Loss: 0.5918,auc: 0.8823\n",
      "Epoch: 016, Loss: 0.5858,auc: 0.8843\n",
      "Epoch: 017, Loss: 0.5796,auc: 0.8862\n",
      "Epoch: 018, Loss: 0.5745,auc: 0.8876\n",
      "Epoch: 019, Loss: 0.5701,auc: 0.8875\n",
      "Epoch: 020, Loss: 0.5655,auc: 0.8865\n",
      "Epoch: 021, Loss: 0.5622,auc: 0.8866\n",
      "Epoch: 022, Loss: 0.5592,auc: 0.8882\n",
      "Epoch: 023, Loss: 0.5568,auc: 0.8885\n",
      "Epoch: 024, Loss: 0.5552,auc: 0.8861\n",
      "Epoch: 025, Loss: 0.5536,auc: 0.8834\n",
      "Epoch: 026, Loss: 0.5531,auc: 0.8839\n",
      "Epoch: 027, Loss: 0.5525,auc: 0.8848\n",
      "Epoch: 028, Loss: 0.5528,auc: 0.8826\n",
      "Epoch: 029, Loss: 0.5528,auc: 0.8794\n",
      "Epoch: 030, Loss: 0.5534,auc: 0.8799\n",
      "Epoch: 031, Loss: 0.5537,auc: 0.8817\n",
      "Epoch: 032, Loss: 0.5542,auc: 0.8806\n",
      "Epoch: 033, Loss: 0.5542,auc: 0.8787\n",
      "Epoch: 034, Loss: 0.5543,auc: 0.8802\n",
      "Epoch: 035, Loss: 0.5539,auc: 0.8824\n",
      "Epoch: 036, Loss: 0.5537,auc: 0.8820\n",
      "Epoch: 037, Loss: 0.5532,auc: 0.8816\n",
      "Epoch: 038, Loss: 0.5527,auc: 0.8839\n",
      "Epoch: 039, Loss: 0.5520,auc: 0.8860\n",
      "Epoch: 040, Loss: 0.5515,auc: 0.8860\n",
      "Epoch: 041, Loss: 0.5509,auc: 0.8866\n",
      "Epoch: 042, Loss: 0.5505,auc: 0.8888\n",
      "Epoch: 043, Loss: 0.5501,auc: 0.8901\n",
      "Epoch: 044, Loss: 0.5498,auc: 0.8900\n",
      "Epoch: 045, Loss: 0.5495,auc: 0.8908\n",
      "Epoch: 046, Loss: 0.5494,auc: 0.8923\n",
      "Epoch: 047, Loss: 0.5493,auc: 0.8926\n",
      "Epoch: 048, Loss: 0.5493,auc: 0.8923\n",
      "Epoch: 049, Loss: 0.5493,auc: 0.8931\n",
      "Epoch: 050, Loss: 0.5492,auc: 0.8937\n",
      "Epoch: 051, Loss: 0.5493,auc: 0.8933\n",
      "Epoch: 052, Loss: 0.5492,auc: 0.8932\n",
      "Epoch: 053, Loss: 0.5492,auc: 0.8938\n",
      "Epoch: 054, Loss: 0.5491,auc: 0.8936\n",
      "Epoch: 055, Loss: 0.5490,auc: 0.8930\n",
      "Epoch: 056, Loss: 0.5489,auc: 0.8932\n",
      "Epoch: 057, Loss: 0.5488,auc: 0.8933\n",
      "Epoch: 058, Loss: 0.5486,auc: 0.8925\n",
      "Epoch: 059, Loss: 0.5485,auc: 0.8924\n",
      "Epoch: 060, Loss: 0.5483,auc: 0.8925\n",
      "Epoch: 061, Loss: 0.5482,auc: 0.8919\n",
      "Epoch: 062, Loss: 0.5480,auc: 0.8915\n",
      "Epoch: 063, Loss: 0.5479,auc: 0.8916\n",
      "Epoch: 064, Loss: 0.5478,auc: 0.8911\n",
      "Epoch: 065, Loss: 0.5477,auc: 0.8906\n",
      "Epoch: 066, Loss: 0.5477,auc: 0.8908\n",
      "Epoch: 067, Loss: 0.5476,auc: 0.8903\n",
      "Epoch: 068, Loss: 0.5475,auc: 0.8900\n",
      "Epoch: 069, Loss: 0.5475,auc: 0.8902\n",
      "Epoch: 070, Loss: 0.5474,auc: 0.8899\n",
      "Epoch: 071, Loss: 0.5474,auc: 0.8897\n",
      "Epoch: 072, Loss: 0.5473,auc: 0.8900\n",
      "Epoch: 073, Loss: 0.5472,auc: 0.8898\n",
      "Epoch: 074, Loss: 0.5471,auc: 0.8899\n",
      "Epoch: 075, Loss: 0.5471,auc: 0.8902\n",
      "Epoch: 076, Loss: 0.5470,auc: 0.8900\n",
      "Epoch: 077, Loss: 0.5469,auc: 0.8903\n",
      "Epoch: 078, Loss: 0.5468,auc: 0.8905\n",
      "Epoch: 079, Loss: 0.5468,auc: 0.8904\n",
      "Epoch: 080, Loss: 0.5467,auc: 0.8908\n",
      "Epoch: 081, Loss: 0.5466,auc: 0.8908\n",
      "Epoch: 082, Loss: 0.5466,auc: 0.8909\n",
      "Epoch: 083, Loss: 0.5465,auc: 0.8912\n",
      "Epoch: 084, Loss: 0.5465,auc: 0.8910\n",
      "Epoch: 085, Loss: 0.5464,auc: 0.8913\n",
      "Epoch: 086, Loss: 0.5464,auc: 0.8912\n",
      "Epoch: 087, Loss: 0.5463,auc: 0.8913\n",
      "Epoch: 088, Loss: 0.5463,auc: 0.8914\n",
      "Epoch: 089, Loss: 0.5462,auc: 0.8912\n",
      "Epoch: 090, Loss: 0.5462,auc: 0.8914\n",
      "Epoch: 091, Loss: 0.5461,auc: 0.8912\n",
      "Epoch: 092, Loss: 0.5460,auc: 0.8914\n",
      "Epoch: 093, Loss: 0.5460,auc: 0.8911\n",
      "Epoch: 094, Loss: 0.5459,auc: 0.8913\n",
      "Epoch: 095, Loss: 0.5459,auc: 0.8910\n",
      "Epoch: 096, Loss: 0.5459,auc: 0.8913\n",
      "Epoch: 097, Loss: 0.5458,auc: 0.8909\n",
      "Epoch: 098, Loss: 0.5458,auc: 0.8914\n",
      "Epoch: 099, Loss: 0.5457,auc: 0.8906\n",
      "Epoch: 100, Loss: 0.5457,auc: 0.8918\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train(train_data)\n",
    "    auc = test(test_data)\n",
    "\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f},auc: {:.4f}'\n",
    "    if epoch % 1 == 0:\n",
    "        print(log.format(epoch, loss, auc ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a40f1-9296-4744-b700-153c51793b41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11dcb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9feea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x,data.edge_index)\n",
    "        pos_edge_index=data.pos_edge_label_index\n",
    "        neg_edge_index=data.neg_edge_label_index\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00e1bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5cc4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs_3/GAE_experiment'+'20d_100_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0d2a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.7485, AP: 0.6955\n",
      "Epoch: 002, AUC: 0.7605, AP: 0.7116\n",
      "Epoch: 003, AUC: 0.7772, AP: 0.7329\n",
      "Epoch: 004, AUC: 0.7943, AP: 0.7550\n",
      "Epoch: 005, AUC: 0.8109, AP: 0.7766\n",
      "Epoch: 006, AUC: 0.8262, AP: 0.7965\n",
      "Epoch: 007, AUC: 0.8386, AP: 0.8128\n",
      "Epoch: 008, AUC: 0.8479, AP: 0.8255\n",
      "Epoch: 009, AUC: 0.8553, AP: 0.8358\n",
      "Epoch: 010, AUC: 0.8618, AP: 0.8449\n",
      "Epoch: 011, AUC: 0.8676, AP: 0.8530\n",
      "Epoch: 012, AUC: 0.8722, AP: 0.8599\n",
      "Epoch: 013, AUC: 0.8757, AP: 0.8653\n",
      "Epoch: 014, AUC: 0.8785, AP: 0.8696\n",
      "Epoch: 015, AUC: 0.8810, AP: 0.8733\n",
      "Epoch: 016, AUC: 0.8826, AP: 0.8763\n",
      "Epoch: 017, AUC: 0.8832, AP: 0.8784\n",
      "Epoch: 018, AUC: 0.8835, AP: 0.8800\n",
      "Epoch: 019, AUC: 0.8847, AP: 0.8818\n",
      "Epoch: 020, AUC: 0.8859, AP: 0.8834\n",
      "Epoch: 021, AUC: 0.8854, AP: 0.8836\n",
      "Epoch: 022, AUC: 0.8842, AP: 0.8832\n",
      "Epoch: 023, AUC: 0.8849, AP: 0.8838\n",
      "Epoch: 024, AUC: 0.8858, AP: 0.8844\n",
      "Epoch: 025, AUC: 0.8840, AP: 0.8831\n",
      "Epoch: 026, AUC: 0.8818, AP: 0.8813\n",
      "Epoch: 027, AUC: 0.8822, AP: 0.8815\n",
      "Epoch: 028, AUC: 0.8824, AP: 0.8813\n",
      "Epoch: 029, AUC: 0.8802, AP: 0.8794\n",
      "Epoch: 030, AUC: 0.8796, AP: 0.8787\n",
      "Epoch: 031, AUC: 0.8812, AP: 0.8798\n",
      "Epoch: 032, AUC: 0.8807, AP: 0.8791\n",
      "Epoch: 033, AUC: 0.8798, AP: 0.8782\n",
      "Epoch: 034, AUC: 0.8818, AP: 0.8796\n",
      "Epoch: 035, AUC: 0.8827, AP: 0.8801\n",
      "Epoch: 036, AUC: 0.8823, AP: 0.8796\n",
      "Epoch: 037, AUC: 0.8842, AP: 0.8810\n",
      "Epoch: 038, AUC: 0.8857, AP: 0.8821\n",
      "Epoch: 039, AUC: 0.8858, AP: 0.8820\n",
      "Epoch: 040, AUC: 0.8874, AP: 0.8832\n",
      "Epoch: 041, AUC: 0.8890, AP: 0.8844\n",
      "Epoch: 042, AUC: 0.8892, AP: 0.8845\n",
      "Epoch: 043, AUC: 0.8907, AP: 0.8856\n",
      "Epoch: 044, AUC: 0.8918, AP: 0.8865\n",
      "Epoch: 045, AUC: 0.8920, AP: 0.8866\n",
      "Epoch: 046, AUC: 0.8931, AP: 0.8875\n",
      "Epoch: 047, AUC: 0.8937, AP: 0.8879\n",
      "Epoch: 048, AUC: 0.8936, AP: 0.8879\n",
      "Epoch: 049, AUC: 0.8945, AP: 0.8887\n",
      "Epoch: 050, AUC: 0.8945, AP: 0.8886\n",
      "Epoch: 051, AUC: 0.8946, AP: 0.8887\n",
      "Epoch: 052, AUC: 0.8951, AP: 0.8892\n",
      "Epoch: 053, AUC: 0.8947, AP: 0.8888\n",
      "Epoch: 054, AUC: 0.8949, AP: 0.8891\n",
      "Epoch: 055, AUC: 0.8949, AP: 0.8891\n",
      "Epoch: 056, AUC: 0.8944, AP: 0.8888\n",
      "Epoch: 057, AUC: 0.8947, AP: 0.8891\n",
      "Epoch: 058, AUC: 0.8940, AP: 0.8886\n",
      "Epoch: 059, AUC: 0.8940, AP: 0.8887\n",
      "Epoch: 060, AUC: 0.8937, AP: 0.8885\n",
      "Epoch: 061, AUC: 0.8932, AP: 0.8882\n",
      "Epoch: 062, AUC: 0.8932, AP: 0.8883\n",
      "Epoch: 063, AUC: 0.8925, AP: 0.8877\n",
      "Epoch: 064, AUC: 0.8927, AP: 0.8880\n",
      "Epoch: 065, AUC: 0.8918, AP: 0.8873\n",
      "Epoch: 066, AUC: 0.8921, AP: 0.8877\n",
      "Epoch: 067, AUC: 0.8913, AP: 0.8871\n",
      "Epoch: 068, AUC: 0.8917, AP: 0.8875\n",
      "Epoch: 069, AUC: 0.8908, AP: 0.8868\n",
      "Epoch: 070, AUC: 0.8915, AP: 0.8874\n",
      "Epoch: 071, AUC: 0.8904, AP: 0.8865\n",
      "Epoch: 072, AUC: 0.8918, AP: 0.8877\n",
      "Epoch: 073, AUC: 0.8896, AP: 0.8859\n",
      "Epoch: 074, AUC: 0.8926, AP: 0.8884\n",
      "Epoch: 075, AUC: 0.8889, AP: 0.8853\n",
      "Epoch: 076, AUC: 0.8928, AP: 0.8886\n",
      "Epoch: 077, AUC: 0.8902, AP: 0.8864\n",
      "Epoch: 078, AUC: 0.8912, AP: 0.8873\n",
      "Epoch: 079, AUC: 0.8926, AP: 0.8884\n",
      "Epoch: 080, AUC: 0.8900, AP: 0.8862\n",
      "Epoch: 081, AUC: 0.8929, AP: 0.8886\n",
      "Epoch: 082, AUC: 0.8916, AP: 0.8874\n",
      "Epoch: 083, AUC: 0.8914, AP: 0.8872\n",
      "Epoch: 084, AUC: 0.8933, AP: 0.8888\n",
      "Epoch: 085, AUC: 0.8911, AP: 0.8869\n",
      "Epoch: 086, AUC: 0.8929, AP: 0.8883\n",
      "Epoch: 087, AUC: 0.8927, AP: 0.8882\n",
      "Epoch: 088, AUC: 0.8916, AP: 0.8871\n",
      "Epoch: 089, AUC: 0.8935, AP: 0.8888\n",
      "Epoch: 090, AUC: 0.8919, AP: 0.8873\n",
      "Epoch: 091, AUC: 0.8927, AP: 0.8880\n",
      "Epoch: 092, AUC: 0.8931, AP: 0.8883\n",
      "Epoch: 093, AUC: 0.8918, AP: 0.8871\n",
      "Epoch: 094, AUC: 0.8934, AP: 0.8886\n",
      "Epoch: 095, AUC: 0.8921, AP: 0.8873\n",
      "Epoch: 096, AUC: 0.8927, AP: 0.8879\n",
      "Epoch: 097, AUC: 0.8929, AP: 0.8881\n",
      "Epoch: 098, AUC: 0.8920, AP: 0.8872\n",
      "Epoch: 099, AUC: 0.8933, AP: 0.8884\n",
      "Epoch: 100, AUC: 0.8920, AP: 0.8872\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748d327-08b3-47a1-8550-f42b2e23831f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DeepGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e1f4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DeepGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, 2 * out_channels, cached=True)\n",
    "        self.conv3 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_weight=None):\n",
    "        x = self.conv1(x, edge_index,edge_weight=edge_weight).relu()\n",
    "        x = self.conv2(x, edge_index,edge_weight=edge_weight).relu()\n",
    "        return self.conv3(x, edge_index,edge_weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e9e4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model\n",
    "model = GAE(DeepGCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f50e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:21<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/DeepGAE_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e84e7-374f-4cea-b995-ebfdcc7f768c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134f60ad-6b22-449a-8203-a38669bcfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8d4c77d-ace6-403c-95aa-d2c6980defff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels)) \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e23185a-a8a5-4cd2-9233-3345a8e22921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VGAE(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss = loss + (1 / data.x.shape[0]) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05df5ae6-ec71-4cca-b657-0ee50af874f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:25<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/VGAE_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_VGAE(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bcda6-3539-4eb5-9d59-c2e98e344ff6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ARGVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0221ac3c-9942-4338-8a15-ec725fa0ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "    \n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d671dbf-d5fa-4ad1-9c6c-7137d48f6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ARGVA(data):\n",
    "    model.train()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    \n",
    "    for i in range(5):  \n",
    "        #discriminator.train()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        discriminator_loss = model.discriminator_loss(z)\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    " \n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss = loss + model.reg_loss(z)\n",
    "    loss = loss + (1 / data.x.shape[0]) * model.kl_loss()\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1345ff5-3748-44c6-9ed5-f9fa7fc0f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "encoder = VariationalGCNEncoder(num_features, embedding)\n",
    "\n",
    "discriminator = Discriminator(in_channels=embedding, hidden_channels=embedding//2, \n",
    "                              out_channels=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ARGVA(encoder, discriminator)\n",
    "model = model.to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8e9a282-d065-4833-9144-a9fa499c252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:46<00:00,  3.46s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/ARGVA_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_ARGVA(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441abb97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b94fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.lin1 = Linear(latent_dim,latent_dim)\n",
    "        self.lin2 = Linear(latent_dim,latent_dim//2)\n",
    "        self.lin3 = Linear(latent_dim//2,1)\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "\n",
    "        z = (z[edge_index[0]] * z[edge_index[1]])#.sum(dim=1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.lin3(z)\n",
    "        z=z.squeeze()\n",
    "        \n",
    "        return torch.sigmoid(z) if sigmoid else value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2aec3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(GCNEncoder(num_features, out_channels),GCNDecoder(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b8c4ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:24<00:00,  3.24s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/GAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591a1fa-2de3-4bdf-aff4-18bf15171fab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DeepGAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b1dc8ae-9317-4c20-bb89-d7068073c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(DeepGCNEncoder(num_features, out_channels),GCNDecoder(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c0468bb-5e87-4787-8b38-4e40fbe33f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [07:59<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/DeepGAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd55894-a9dc-469e-9ab8-da1bbd83267a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VGAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f2cc3ed-e3b3-4ec1-b58d-c27cab592190",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels),GCNDecoder(out_channels)) \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd20ae48-e32f-4c3a-ad5f-b16955ff01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:33<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/VGAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_VGAE(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f069b-724a-407a-bbc4-b84e119c3bca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ARGVA with linear Decoder (AUC e AP basse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "af98615f-b11a-4df4-aa85-88eab7596f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_sig(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "        return torch.sigmoid(self.lin3(x))#added sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf6a0ac8-7ced-43b0-b07f-a34a3d22804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 10   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "encoder = VariationalGCNEncoder(num_features, embedding)\n",
    "\n",
    "#discriminator = Discriminator(in_channels=embedding, hidden_channels=embedding//2, \n",
    "#                              out_channels=1)\n",
    "    \n",
    "discriminator = Discriminator_sig(in_channels=embedding, hidden_channels=embedding//2, \n",
    "                              out_channels=1)\n",
    "decoder=GCNDecoder(embedding)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ARGVA(encoder, discriminator,decoder)\n",
    "model = model.to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)#0.001\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)#0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de9b13-a336-4d04-a45e-1c168135a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs_3/ARGVAsig+dec_experiment'+'10d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_ARGVA(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045f09c-c96c-4774-9d3b-a461e9427442",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE with RGCN (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b605fb6e-ad60-449c-946c-6218bb949143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        self.node_emb = Parameter(torch.Tensor(num_nodes, hidden_channels))\n",
    "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=1)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_emb)\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.node_emb\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5763dbe6-ed9e-419d-b0e5-3f05f2cefb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.rel_emb = Parameter(torch.Tensor(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8aaa602b-5e7a-4d57-adc5-f0a68ac4e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 10   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(\n",
    "    RGCNEncoder(train_data.num_nodes, hidden_channels=5,\n",
    "                num_relations=train_data.num_edges),\n",
    "    DistMultDecoder(train_data.num_edges // 2, hidden_channels=500),\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ae67eb02-89ef-4458-a424-b9e5d32c503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAE(\n",
       "  (encoder): RGCNEncoder(\n",
       "    (conv1): RGCNConv(5, 5, num_relations=1118815)\n",
       "    (conv2): RGCNConv(5, 5, num_relations=1118815)\n",
       "  )\n",
       "  (decoder): DistMultDecoder()\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ca87d9c0-4f46-4df7-b5c4-9f3987576901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7984/444824558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7984/3454188936.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpos_edge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_edge_label_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mneg_edge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_edge_label_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch_geometric\\nn\\models\\autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;34mr\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7984/264102021.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, edge_index, edge_type)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_emb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\rgcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_type)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_relations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasked_edge_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                 \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\rgcn_conv.py\u001b[0m in \u001b[0;36mmasked_edge_index\u001b[1;34m(edge_index, edge_mask)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmasked_edge_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmasked_select_nnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/GAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f333bc2-9213-4385-bb1e-2ca41325eda0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE with Decoder 2 (AUC e AP salgono prima, but same result of inner product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5bfee99-be12-40dd-96e5-6aa3aad74c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDecoder_concat(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(GCNDecoder_concat, self).__init__()\n",
    "        self.lin1 = Linear(latent_dim*2,latent_dim)\n",
    "        self.lin2 = Linear(latent_dim,latent_dim//2)\n",
    "        self.lin3 = Linear(latent_dim//2,1)\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "\n",
    "        #z = (z[edge_index[0]] * z[edge_index[1]])#.sum(dim=1)\n",
    "        z = torch.cat((z[edge_index[0]], z[edge_index[1]]),dim=1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.lin3(z)\n",
    "        z=z.squeeze()\n",
    "        \n",
    "        return torch.sigmoid(z) if sigmoid else value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13be003a-35ba-49d4-81ea-714d349e67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(GCNEncoder(num_features, out_channels),GCNDecoder_concat(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5f8cdda-ce2b-4458-b8a9-5a90e5bc704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:14<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/GAE+dec_2_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee31b4-f322-49dd-8e18-8b82bd667bd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DeepGAE with Decoder 2 (oscilla troppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c306a39a-f8a5-44bf-bccf-0788bf8d4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 10   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(DeepGCNEncoder(num_features, out_channels),GCNDecoder_concat(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d93c0ac7-f746-4ea9-bb2b-0ddc9175c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [03:38<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/DeepGAE+dec_2_experiment'+'10d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6b595-6ced-43f5-afa5-9bd07abc32f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
