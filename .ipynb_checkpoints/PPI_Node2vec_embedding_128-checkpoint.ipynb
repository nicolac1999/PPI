{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ef28a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,Linear\n",
    "from torch_geometric.nn import GAE, Node2Vec,VGAE\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn.models.autoencoder import ARGVA\n",
    "\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167995cc-eaf5-4878-80de-fc4caf59bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2219b8545b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9289db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\calni\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch_geometric\\utils\\convert.py:178: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  data[key] = torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df=pd.read_csv('PPI.csv')\n",
    "G=nx.from_pandas_edgelist(df,'Official Symbol Interactor A','Official Symbol Interactor B' )\n",
    "#Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "#G0 = G.subgraph(Gcc[0])\n",
    "G=nx.convert_node_labels_to_integers(G)\n",
    "pyg_graph = from_networkx(G)\n",
    "\n",
    "node_embedding=Node2Vec(pyg_graph.edge_index,20,16,10)\n",
    "\n",
    "#embedding del nodo 0\n",
    "#node_embedding.forward().data[0]# cambia ogni volta anche con il seed \n",
    "\n",
    "#aggiungiamo gli embedding come features dei nodi\n",
    "for n in G.nodes():\n",
    "    G.nodes[n]['x']=np.array(node_embedding.forward().data[n])\n",
    "    \n",
    "pyg_graph = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566b7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(is_undirected=False,split_labels=True,\n",
    "                      neg_sampling_ratio=1.0,\n",
    "                      key = \"edge_label\",\n",
    "                      disjoint_train_ratio=0,\n",
    "                      num_val =0)\n",
    "train_data, val_data, test_data = transform(pyg_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a40f1-9296-4744-b700-153c51793b41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11dcb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9feea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x,data.edge_index)\n",
    "        pos_edge_index=data.pos_edge_label_index\n",
    "        neg_edge_index=data.neg_edge_label_index\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00e1bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5cc4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs_3/GAE_experiment'+'20d_100_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0d2a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.7485, AP: 0.6955\n",
      "Epoch: 002, AUC: 0.7605, AP: 0.7116\n",
      "Epoch: 003, AUC: 0.7772, AP: 0.7329\n",
      "Epoch: 004, AUC: 0.7943, AP: 0.7550\n",
      "Epoch: 005, AUC: 0.8109, AP: 0.7766\n",
      "Epoch: 006, AUC: 0.8262, AP: 0.7965\n",
      "Epoch: 007, AUC: 0.8386, AP: 0.8128\n",
      "Epoch: 008, AUC: 0.8479, AP: 0.8255\n",
      "Epoch: 009, AUC: 0.8553, AP: 0.8358\n",
      "Epoch: 010, AUC: 0.8618, AP: 0.8449\n",
      "Epoch: 011, AUC: 0.8676, AP: 0.8530\n",
      "Epoch: 012, AUC: 0.8722, AP: 0.8599\n",
      "Epoch: 013, AUC: 0.8757, AP: 0.8653\n",
      "Epoch: 014, AUC: 0.8785, AP: 0.8696\n",
      "Epoch: 015, AUC: 0.8810, AP: 0.8733\n",
      "Epoch: 016, AUC: 0.8826, AP: 0.8763\n",
      "Epoch: 017, AUC: 0.8832, AP: 0.8784\n",
      "Epoch: 018, AUC: 0.8835, AP: 0.8800\n",
      "Epoch: 019, AUC: 0.8847, AP: 0.8818\n",
      "Epoch: 020, AUC: 0.8859, AP: 0.8834\n",
      "Epoch: 021, AUC: 0.8854, AP: 0.8836\n",
      "Epoch: 022, AUC: 0.8842, AP: 0.8832\n",
      "Epoch: 023, AUC: 0.8849, AP: 0.8838\n",
      "Epoch: 024, AUC: 0.8858, AP: 0.8844\n",
      "Epoch: 025, AUC: 0.8840, AP: 0.8831\n",
      "Epoch: 026, AUC: 0.8818, AP: 0.8813\n",
      "Epoch: 027, AUC: 0.8822, AP: 0.8815\n",
      "Epoch: 028, AUC: 0.8824, AP: 0.8813\n",
      "Epoch: 029, AUC: 0.8802, AP: 0.8794\n",
      "Epoch: 030, AUC: 0.8796, AP: 0.8787\n",
      "Epoch: 031, AUC: 0.8812, AP: 0.8798\n",
      "Epoch: 032, AUC: 0.8807, AP: 0.8791\n",
      "Epoch: 033, AUC: 0.8798, AP: 0.8782\n",
      "Epoch: 034, AUC: 0.8818, AP: 0.8796\n",
      "Epoch: 035, AUC: 0.8827, AP: 0.8801\n",
      "Epoch: 036, AUC: 0.8823, AP: 0.8796\n",
      "Epoch: 037, AUC: 0.8842, AP: 0.8810\n",
      "Epoch: 038, AUC: 0.8857, AP: 0.8821\n",
      "Epoch: 039, AUC: 0.8858, AP: 0.8820\n",
      "Epoch: 040, AUC: 0.8874, AP: 0.8832\n",
      "Epoch: 041, AUC: 0.8890, AP: 0.8844\n",
      "Epoch: 042, AUC: 0.8892, AP: 0.8845\n",
      "Epoch: 043, AUC: 0.8907, AP: 0.8856\n",
      "Epoch: 044, AUC: 0.8918, AP: 0.8865\n",
      "Epoch: 045, AUC: 0.8920, AP: 0.8866\n",
      "Epoch: 046, AUC: 0.8931, AP: 0.8875\n",
      "Epoch: 047, AUC: 0.8937, AP: 0.8879\n",
      "Epoch: 048, AUC: 0.8936, AP: 0.8879\n",
      "Epoch: 049, AUC: 0.8945, AP: 0.8887\n",
      "Epoch: 050, AUC: 0.8945, AP: 0.8886\n",
      "Epoch: 051, AUC: 0.8946, AP: 0.8887\n",
      "Epoch: 052, AUC: 0.8951, AP: 0.8892\n",
      "Epoch: 053, AUC: 0.8947, AP: 0.8888\n",
      "Epoch: 054, AUC: 0.8949, AP: 0.8891\n",
      "Epoch: 055, AUC: 0.8949, AP: 0.8891\n",
      "Epoch: 056, AUC: 0.8944, AP: 0.8888\n",
      "Epoch: 057, AUC: 0.8947, AP: 0.8891\n",
      "Epoch: 058, AUC: 0.8940, AP: 0.8886\n",
      "Epoch: 059, AUC: 0.8940, AP: 0.8887\n",
      "Epoch: 060, AUC: 0.8937, AP: 0.8885\n",
      "Epoch: 061, AUC: 0.8932, AP: 0.8882\n",
      "Epoch: 062, AUC: 0.8932, AP: 0.8883\n",
      "Epoch: 063, AUC: 0.8925, AP: 0.8877\n",
      "Epoch: 064, AUC: 0.8927, AP: 0.8880\n",
      "Epoch: 065, AUC: 0.8918, AP: 0.8873\n",
      "Epoch: 066, AUC: 0.8921, AP: 0.8877\n",
      "Epoch: 067, AUC: 0.8913, AP: 0.8871\n",
      "Epoch: 068, AUC: 0.8917, AP: 0.8875\n",
      "Epoch: 069, AUC: 0.8908, AP: 0.8868\n",
      "Epoch: 070, AUC: 0.8915, AP: 0.8874\n",
      "Epoch: 071, AUC: 0.8904, AP: 0.8865\n",
      "Epoch: 072, AUC: 0.8918, AP: 0.8877\n",
      "Epoch: 073, AUC: 0.8896, AP: 0.8859\n",
      "Epoch: 074, AUC: 0.8926, AP: 0.8884\n",
      "Epoch: 075, AUC: 0.8889, AP: 0.8853\n",
      "Epoch: 076, AUC: 0.8928, AP: 0.8886\n",
      "Epoch: 077, AUC: 0.8902, AP: 0.8864\n",
      "Epoch: 078, AUC: 0.8912, AP: 0.8873\n",
      "Epoch: 079, AUC: 0.8926, AP: 0.8884\n",
      "Epoch: 080, AUC: 0.8900, AP: 0.8862\n",
      "Epoch: 081, AUC: 0.8929, AP: 0.8886\n",
      "Epoch: 082, AUC: 0.8916, AP: 0.8874\n",
      "Epoch: 083, AUC: 0.8914, AP: 0.8872\n",
      "Epoch: 084, AUC: 0.8933, AP: 0.8888\n",
      "Epoch: 085, AUC: 0.8911, AP: 0.8869\n",
      "Epoch: 086, AUC: 0.8929, AP: 0.8883\n",
      "Epoch: 087, AUC: 0.8927, AP: 0.8882\n",
      "Epoch: 088, AUC: 0.8916, AP: 0.8871\n",
      "Epoch: 089, AUC: 0.8935, AP: 0.8888\n",
      "Epoch: 090, AUC: 0.8919, AP: 0.8873\n",
      "Epoch: 091, AUC: 0.8927, AP: 0.8880\n",
      "Epoch: 092, AUC: 0.8931, AP: 0.8883\n",
      "Epoch: 093, AUC: 0.8918, AP: 0.8871\n",
      "Epoch: 094, AUC: 0.8934, AP: 0.8886\n",
      "Epoch: 095, AUC: 0.8921, AP: 0.8873\n",
      "Epoch: 096, AUC: 0.8927, AP: 0.8879\n",
      "Epoch: 097, AUC: 0.8929, AP: 0.8881\n",
      "Epoch: 098, AUC: 0.8920, AP: 0.8872\n",
      "Epoch: 099, AUC: 0.8933, AP: 0.8884\n",
      "Epoch: 100, AUC: 0.8920, AP: 0.8872\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748d327-08b3-47a1-8550-f42b2e23831f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DeepGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e1f4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DeepGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, 2 * out_channels, cached=True)\n",
    "        self.conv3 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_weight=None):\n",
    "        x = self.conv1(x, edge_index,edge_weight=edge_weight).relu()\n",
    "        x = self.conv2(x, edge_index,edge_weight=edge_weight).relu()\n",
    "        return self.conv3(x, edge_index,edge_weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e9e4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model\n",
    "model = GAE(DeepGCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f50e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:21<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/DeepGAE_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e84e7-374f-4cea-b995-ebfdcc7f768c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134f60ad-6b22-449a-8203-a38669bcfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8d4c77d-ace6-403c-95aa-d2c6980defff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels)) \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e23185a-a8a5-4cd2-9233-3345a8e22921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VGAE(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss = loss + (1 / data.x.shape[0]) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05df5ae6-ec71-4cca-b657-0ee50af874f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:25<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/VGAE_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_VGAE(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bcda6-3539-4eb5-9d59-c2e98e344ff6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ARGVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0221ac3c-9942-4338-8a15-ec725fa0ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "    \n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d671dbf-d5fa-4ad1-9c6c-7137d48f6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ARGVA(data):\n",
    "    model.train()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    pos_edge_index=data.pos_edge_label_index\n",
    "    neg_edge_index=data.neg_edge_label_index\n",
    "    \n",
    "    for i in range(5):  \n",
    "        #discriminator.train()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        discriminator_loss = model.discriminator_loss(z)\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    " \n",
    "    loss = model.recon_loss(z, pos_edge_index,neg_edge_index) \n",
    "    loss = loss + model.reg_loss(z)\n",
    "    loss = loss + (1 / data.x.shape[0]) * model.kl_loss()\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1345ff5-3748-44c6-9ed5-f9fa7fc0f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "encoder = VariationalGCNEncoder(num_features, embedding)\n",
    "\n",
    "discriminator = Discriminator(in_channels=embedding, hidden_channels=embedding//2, \n",
    "                              out_channels=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ARGVA(encoder, discriminator)\n",
    "model = model.to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8e9a282-d065-4833-9144-a9fa499c252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:46<00:00,  3.46s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/ARGVA_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_ARGVA(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441abb97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b94fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.lin1 = Linear(latent_dim,latent_dim)\n",
    "        self.lin2 = Linear(latent_dim,latent_dim//2)\n",
    "        self.lin3 = Linear(latent_dim//2,1)\n",
    "\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "\n",
    "        z = (z[edge_index[0]] * z[edge_index[1]])#.sum(dim=1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z).relu()\n",
    "        z = self.lin3(z)\n",
    "        z=z.squeeze()\n",
    "        \n",
    "        return torch.sigmoid(z) if sigmoid else value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2aec3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(GCNEncoder(num_features, out_channels),GCNDecoder(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b8c4ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [05:24<00:00,  3.24s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/GAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591a1fa-2de3-4bdf-aff4-18bf15171fab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DeepGAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b1dc8ae-9317-4c20-bb89-d7068073c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAE(DeepGCNEncoder(num_features, out_channels),GCNDecoder(out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c0468bb-5e87-4787-8b38-4e40fbe33f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [07:59<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/DeepGAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd55894-a9dc-469e-9ab8-da1bbd83267a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VGAE with Linear Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f2cc3ed-e3b3-4ec1-b58d-c27cab592190",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 20   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels),GCNDecoder(out_channels)) \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd20ae48-e32f-4c3a-ad5f-b16955ff01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [06:33<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs_3/VGAE+dec_experiment'+'20d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_VGAE(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f069b-724a-407a-bbc4-b84e119c3bca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ARGVA with linear Decoder (AUC e AP basse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "af98615f-b11a-4df4-aa85-88eab7596f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_sig(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x).relu()\n",
    "        return torch.sigmoid(self.lin3(x))#added sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf6a0ac8-7ced-43b0-b07f-a34a3d22804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 10   #embedding \n",
    "num_features = train_data.x.shape[1] \n",
    "epochs = 100\n",
    "\n",
    "encoder = VariationalGCNEncoder(num_features, embedding)\n",
    "\n",
    "#discriminator = Discriminator(in_channels=embedding, hidden_channels=embedding//2, \n",
    "#                              out_channels=1)\n",
    "    \n",
    "discriminator = Discriminator_sig(in_channels=embedding, hidden_channels=embedding//2, \n",
    "                              out_channels=1)\n",
    "decoder=GCNDecoder(embedding)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ARGVA(encoder, discriminator,decoder)\n",
    "model = model.to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)#0.001\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)#0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de9b13-a336-4d04-a45e-1c168135a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs_3/ARGVAsig+dec_experiment'+'10d_100_epochs')\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train_ARGVA(train_data)\n",
    "    auc, ap = test(test_data)\n",
    "    #print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    writer.add_scalar('loss train',loss,epoch)\n",
    "    writer.add_scalar('auc train',auc,epoch) \n",
    "    writer.add_scalar('ap train',ap,epoch) \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605fb6e-ad60-449c-946c-6218bb949143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763dbe6-ed9e-419d-b0e5-3f05f2cefb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa602b-5e7a-4d57-adc5-f0a68ac4e2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
